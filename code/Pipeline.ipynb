{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33dbb554-3240-4b9e-aaf4-107880f38e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30900120-ce71-417a-a300-cac65776294e",
   "metadata": {},
   "source": [
    "---\n",
    "### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9505db40-4311-40d8-a5b8-a0896fc715cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar_train = CIFAR100(os.getcwd(), download=True, transform=transform)\n",
    "cifar_test = CIFAR100(os.getcwd(), train = False, transform=transform)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "-------------------------------------------------------\n",
    "Map fine label names to coarse label names\n",
    "\"\"\"\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "meta = unpickle('cifar-100-python/meta')\n",
    "training_set = unpickle('cifar-100-python/train')\n",
    "\n",
    "# CIFAR-100 label names\n",
    "fine_label_names = meta[b'fine_label_names']\n",
    "coarse_label_names = meta[b'coarse_label_names']\n",
    "\n",
    "label_mappings = []   # mappings from fine label to coarse label\n",
    "for fine_label, coarse_label in zip(training_set[b'fine_labels'],training_set[b'coarse_labels']):\n",
    "    if (fine_label, coarse_label) not in label_mappings:\n",
    "        label_mappings.append((fine_label, coarse_label))\n",
    "label_mappings.sort()\n",
    "\n",
    "fine_to_coarse = [label_mapping[1] for label_mapping in label_mappings]   # Also mappings from fine to coarse label but in a list\n",
    "\"\"\"\n",
    "--------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset Class for CIFAR  \n",
    "    \"\"\"\n",
    "    def __init__(self, data, labels, transform = None):\n",
    "        self.data = torch.tensor(data)\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        return self.data[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def getLabeledDataset(dataset: CIFAR100, label):\n",
    "    \"\"\"\n",
    "    Return CustomDataset instance with labels that match the specified label value\n",
    "    \"\"\" \n",
    "    labels = np.array(dataset.targets)\n",
    "    matched_data = dataset.data[labels == label]\n",
    "    return CustomDataset(matched_data, [label]*len(matched_data))\n",
    "    \n",
    "def getFineLabeledDataset(dataset: CIFAR100, fine_label_name):\n",
    "    \"\"\"\n",
    "    Return CustomDataset instance with labels that match the specified fine label name\n",
    "    \"\"\"\n",
    "    return getLabeledDataset(dataset, fine_label_names.index(fine_label_name))\n",
    "\n",
    "def mergeDataset(datasets: list):\n",
    "    \"\"\"\n",
    "    Merge CustomDataset instances (to later be used for binary classification)\n",
    "    \"\"\"\n",
    "    merged_data = np.vstack(tuple(dataset.data for dataset in datasets))\n",
    "    merged_labels = []\n",
    "    for dataset in datasets:\n",
    "        merged_labels += dataset.labels\n",
    "    \n",
    "    return CustomDataset(merged_data, merged_labels)\n",
    "\n",
    "def getCoarseLabeledDataset(dataset: CIFAR100, coarse_label_name):\n",
    "    \"\"\"\n",
    "    Return CustomDataset instance with labels that match the specified fine label name\n",
    "    Fine all the fine labels (classes) within coarse label (superclass) and merge all of the former datasets\n",
    "    \"\"\"\n",
    "    coarse_label_index = coarse_label_names.index(coarse_label_name)\n",
    "    \n",
    "    # list of matched fine label values(int)\n",
    "    matched_labels  = \\\n",
    "    [fine_label_name for fine_label_name, coarse_label_number in enumerate(fine_to_coarse) if coarse_label_number ==  coarse_label_index]\n",
    "    return mergeDataset(list(getLabeledDataset(dataset, matched_label) for matched_label in matched_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b5ada4-56d0-4eeb-9834-c96940447c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "worm_dataset = getFineLabeledDataset(cifar_train,b'worm')\n",
    "aquarium_fish_dataset = getFineLabeledDataset(cifar_train,b'aquarium_fish')\n",
    "worm_aquarium_fish_dataset = mergeDataset([worm_dataset, aquarium_fish_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9f675f-265f-41f6-9033-3c45cb10c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 48,  48,  48],\n",
      "         [ 36,  36,  36],\n",
      "         [ 45,  45,  45],\n",
      "         ...,\n",
      "         [  0,   0,   0],\n",
      "         [  1,   1,   1],\n",
      "         [  1,   1,   1]],\n",
      "\n",
      "        [[ 14,  14,  14],\n",
      "         [  4,   4,   4],\n",
      "         [  4,   4,   4],\n",
      "         ...,\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  1,   1,   1]],\n",
      "\n",
      "        [[  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         ...,\n",
      "         [ 99,  99,  99],\n",
      "         [206, 206, 206],\n",
      "         [125, 125, 125]],\n",
      "\n",
      "        [[  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         ...,\n",
      "         [ 21,  21,  21],\n",
      "         [115, 115, 115],\n",
      "         [ 91,  91,  91]],\n",
      "\n",
      "        [[  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         ...,\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0],\n",
      "         [  0,   0,   0]]], dtype=torch.uint8), tensor(99))\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(worm_aquarium_fish_dataset[0])\n",
    "print(len(worm_aquarium_fish_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13855dab-ec23-4f2b-92e8-c6867261677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aquatic_mammals'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_label_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20c4c13-5416-4756-844f-1983a4a18aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarse label (superclass) 'aquatic mammals' dataset \n",
    "aquatic_mammals = getCoarseLabeledDataset(cifar_test, b'aquatic_mammals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee20cdf-98bf-4de6-b41d-116b7c6e1a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 30, 55, 72, 95])\n",
      "\n",
      "Classes inside superclass 'aquatic mammals'\n",
      "[b'beaver', b'dolphin', b'otter', b'seal', b'whale']\n"
     ]
    }
   ],
   "source": [
    "# set of all fine label value (int: 0->99) belongs to 'aquatic mammals' coarse label\n",
    "print(aquatic_mammals.labels.unique())\n",
    "\n",
    "# name of all fine labels in 'aquatic mammals'\n",
    "print('\\nClasses inside superclass \\'aquatic mammals\\'')\n",
    "print(list(fine_label_names[int(i)] for i in aquatic_mammals.labels.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07d50b-71f1-4c5b-b969-01884e640a4b",
   "metadata": {},
   "source": [
    "----\n",
    "### Building Household Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8ac386-343c-4488-957a-34d15352613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training set\n",
    "furniture_train = getCoarseLabeledDataset(cifar_train, b'household_furniture')\n",
    "furniture_train.labels = torch.ones(len(furniture_train))\n",
    "electrical_train = getCoarseLabeledDataset(cifar_train, b'household_electrical_devices')\n",
    "electrical_train.labels = torch.zeros(len(electrical_train))\n",
    "#print(len(furniture_train))\n",
    "#print(len(electrical_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516f0d99-0d29-46fa-ba84-5d8eedaadf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34048/4127916651.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.data = torch.tensor(data)\n",
      "/tmp/ipykernel_34048/4127916651.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# For simplicity sake, we take the first of 125 (5%) of furniture and 2375 (95%) of electrical devices\n",
    "household_train = mergeDataset([\\\n",
    "    CustomDataset(furniture_train.data[:125], furniture_train.labels[:125]),\n",
    "    CustomDataset(electrical_train.data[:2375], electrical_train.labels[:2375])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5aa111f-cad4-43eb-a5d2-db96d90dec53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "household_train.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aa9d412-12de-4b25-bc85-5092f5381b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing set\n",
    "furniture_test = getCoarseLabeledDataset(cifar_test, b'household_furniture')\n",
    "furniture_test.labels = torch.ones(len(furniture_test))\n",
    "electrical_test = getCoarseLabeledDataset(cifar_test, b'household_electrical_devices')\n",
    "electrical_test.labels = torch.zeros(len(electrical_test))\n",
    "household_test = mergeDataset([furniture_test, electrical_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b7123c-eed5-449b-a014-48d74439bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x7fb6fc7d0640>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "household_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c111d8-dd26-4daa-80b2-4ffc17e59978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "household_train.labels.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b487f91d-b3a1-4bb3-8365-16349ab69069",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader=torch.utils.data.DataLoader(household_train,batch_size=100,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38837e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "872f3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARtrainer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFARtrainer,self).__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.dnn1=nn.Sequential(\n",
    "            nn.Linear(in_features=3072,out_features=1000),\n",
    "            nn.Linear(in_features=1000,out_features=300),\n",
    "            nn.Linear(in_features=300,out_features=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        x=self.dnn1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c3ae588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfe(output1,target1):\n",
    "    out1=[]\n",
    "    tar1=[]\n",
    "    out2=[]\n",
    "    tar2=[]\n",
    "    for i in range(len(target1)): \n",
    "        if (coarse_label_names[output1[i]]==0 and coarse_label_names[target1[i]]==0):\n",
    "            out1.append(output1[i])\n",
    "            tar1.append(target1[i])\n",
    "        if (coarse_label_names[output1[i]]==1 and coarse_label_names[target1[i]]==1):\n",
    "            out2.append(output1[i])\n",
    "            tar2.append(target1[i])\n",
    "    out1=torch.totensor(out1)\n",
    "    tar1=torch.totensor(tar1)\n",
    "    out2=torch.totensor(out2)\n",
    "    tar2=torch.totensor(tar2)\n",
    "    fne = torch.mean((out1 - tar1)**2)\n",
    "    fpe = torch.mean((out2 - tar2)**2)\n",
    "    return fpe+fne\n",
    "def msfe(output,target):\n",
    "    out1=[]\n",
    "    tar1=[]\n",
    "    out2=[]\n",
    "    tar2=[]\n",
    "    for i in range(len(target)): \n",
    "        if (coarse_label_names[output1[i]]==0 and coarse_label_names[target1[i]]==0):\n",
    "            out1.append(output1[i])\n",
    "            tar1.append(target1[i])\n",
    "        if (coarse_label_names[output1[i]]==1 and coarse_label_names[target1[i]]==1):\n",
    "            out2.append(output1[i])\n",
    "            tar2.append(target1[i])\n",
    "    out1=torch.totensor(out1)\n",
    "    tar1=torch.totensor(tar1)\n",
    "    out2=torch.totensor(out2)\n",
    "    tar2=torch.totensor(tar2)\n",
    "    fne = torch.mean((out1 - tar1)**2)\n",
    "    fpe = torch.mean((out2 - tar2)**2)\n",
    "    return fpe**2+fne**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17a1786e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m predict\u001b[38;5;241m=\u001b[39mTRAINER(X\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 13\u001b[0m loss\u001b[38;5;241m=\u001b[39m\u001b[43mmfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mmfe\u001b[0;34m(output1, target1)\u001b[0m\n\u001b[1;32m      5\u001b[0m tar2\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target1)): \n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mcoarse_label_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m coarse_label_names[target1[i]]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      8\u001b[0m         out1\u001b[38;5;241m.\u001b[39mappend(output1[i])\n\u001b[1;32m      9\u001b[0m         tar1\u001b[38;5;241m.\u001b[39mappend(target1[i])\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "TRAINER=CIFARtrainer().float().to(device=\"cuda\")\n",
    "#loss_criterion = mfe()\n",
    "\n",
    "optimizer= torch.optim.Adam(TRAINER.parameters(),lr=0.0008)\n",
    "#start training the model\n",
    "for epoch in range(50):    \n",
    "    for X,y in dataset_loader:\n",
    "        #print(X.shape)\n",
    "        #move data to cuda for operating\n",
    "        X=X.to(device=\"cuda\")\n",
    "        y=y.to(device=\"cuda\")\n",
    "        predict=TRAINER(X.float())\n",
    "        loss=mfe(predict,y.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss for current epoch\",epoch,\":\",loss)\n",
    "    print(\"pred:{},y:{}\".format(predict.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c64805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25014a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
